import os
import asyncio
import tempfile
import json
import base64
import math
import traceback
import re
from collections import defaultdict
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, FSInputFile
from mutagen.id3 import ID3, TIT2, TPE1, APIC
from mutagen.mp3 import MP3
import yt_dlp
import uuid
import time
from spotdl import Spotdl

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# --- Spotify Credentials ---
SPOTIFY_CLIENT_ID = os.getenv('SPOTIFY_CLIENT_ID')
SPOTIFY_CLIENT_SECRET = os.getenv('SPOTIFY_CLIENT_SECRET')
# -------------------------

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=os.getenv('BOT_TOKEN'))
dp = Dispatcher()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
TRACKS_PER_PAGE = 10
MAX_TRACKS = 300
MAX_RETRIES = 3
MIN_SONG_DURATION = 45  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
MAX_SONG_DURATION = 720 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (12 –º–∏–Ω—É—Ç)

# –•—Ä–∞–Ω–∏–ª–∏—â–∞
download_tasks = defaultdict(dict)
search_results = {}
download_queues = defaultdict(list)  # –û—á–µ—Ä–µ–¥–∏ –∑–∞–≥—Ä—É–∑–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
playlist_downloads = {} # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–æ–∫ –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤ {playlist_id: {details...}}
MAX_PARALLEL_DOWNLOADS = 5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ yt-dlp
ydl_opts = {
    # Prioritize m4a, then best audio, then best overall
    'format': 'bestaudio[ext=m4a]/bestaudio/best',
    'postprocessors': [{
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'mp3',
        'preferredquality': '192',
    }],
    'quiet': True,
    'no_warnings': True,
    'extract_flat': True,
    'prefer_ffmpeg': True,
    'nocheckcertificate': True,
    'ignoreerrors': True,
    # Note: 'audioformat', 'audioquality', 'extractaudio', 'keepvideo'
    # are implicitly handled by the postprocessor or are download-specific.
    # 'outtmpl' is better handled dynamically in download_track.
    'ffmpeg_location': '/usr/bin/ffmpeg',
}

def extract_title_and_artist(title):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç—Ä–µ–∫–∞ –∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"""
    # –£–¥–∞–ª—è–µ–º –æ–±—â–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
    prefixes = ['Official Video', 'Official Music Video', 'Official Audio', 'Lyric Video', 'Lyrics', 'Topic']
    for prefix in prefixes:
        if title.lower().endswith(f" - {prefix.lower()}"):
            title = title[:-len(prefix)-3]
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
    separators = [' - ', ' ‚Äî ', ' ‚Äì ', ' | ', ' ~ ']
    for sep in separators:
        if sep in title:
            parts = title.split(sep)
            if len(parts) == 2:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∞—è —á–∞—Å—Ç—å –±–æ–ª—å—à–µ –ø–æ—Ö–æ–∂–∞ –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞
                if len(parts[0]) > len(parts[1]):
                    return parts[0].strip(), parts[1].strip()
                else:
                    return parts[1].strip(), parts[0].strip()
    
    # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –¥–ª–∏–Ω–µ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
    if len(title) > 30:  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –¥–ª–∏–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ - —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞
        return title, "Unknown Artist"
    elif any(char in title for char in ['(', '[', '{']):  # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∫–æ–±–∫–∏, –≤–µ—Ä–æ—è—Ç–Ω–æ —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞
        return title, "Unknown Artist"
    else:
        return title, "Unknown Artist"

async def search_youtube(query, max_results=50):
    try:
        search_opts = {
            **ydl_opts,
            'default_search': 'ytsearch',
            'max_downloads': max_results,
            'extract_flat': True,
        }
        
        with yt_dlp.YoutubeDL(search_opts) as ydl:
            info = ydl.extract_info(f"ytsearch{max_results}:{query}", download=False)
            if not info or 'entries' not in info:
                return []
            
            results = []
            for entry in info['entries']:
                if entry:
                    duration = entry.get('duration', 0)
                    # Filter by duration
                    if not duration or not (MIN_SONG_DURATION <= duration <= MAX_SONG_DURATION):
                        continue # Skip if duration is missing or outside the range
                        
                    title, artist = extract_title_and_artist(entry.get('title', 'Unknown Title'))
                    # –ï—Å–ª–∏ artist –æ—Å—Ç–∞–ª—Å—è Unknown Artist, –∏—Å–ø–æ–ª—å–∑—É–µ–º uploader
                    if artist == "Unknown Artist":
                        artist = entry.get('uploader', 'Unknown Artist')
                    results.append({
                        'title': title,
                        'channel': artist,
                        'url': entry.get('url', ''),
                        'duration': entry.get('duration', 0)
                    })
            return results
    except Exception as e:
        print(f"An error occurred during search: {e}")
        return []

async def search_soundcloud(query, max_results=50):
    """Searches SoundCloud using yt-dlp."""
    try:
        # Use scsearch for SoundCloud
        search_opts = {
            **ydl_opts,
            'default_search': 'scsearch',
            'max_downloads': max_results,
            'extract_flat': True,
        }

        with yt_dlp.YoutubeDL(search_opts) as ydl:
            print(f"[SoundCloud Search Debug] Querying: scsearch{max_results}:{query}") # –î–æ–±–∞–≤–∏–º –ª–æ–≥ –∑–∞–ø—Ä–æ—Å–∞
            info = ydl.extract_info(f"scsearch{max_results}:{query}", download=False)
            
            # –î–æ–±–∞–≤–∏–º –≤—ã–≤–æ–¥ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            print(f"[SoundCloud Search Debug] Raw info received: {info}") 
            
            if not info or 'entries' not in info:
                print("[SoundCloud Search Debug] No info or entries found in response.") # –õ–æ–≥ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                return []

            print(f"[SoundCloud Search Debug] Found {len(info['entries'])} potential entries.") # –õ–æ–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            results = []
            for entry_index, entry in enumerate(info['entries']):
                if entry:
                    duration = entry.get('duration', 0)
                    # Duration from scsearch is already in seconds
                    duration_seconds = duration # Use duration directly
                    
                    # Filter by duration
                    if not duration_seconds or not (MIN_SONG_DURATION <= duration_seconds <= MAX_SONG_DURATION):
                        # Add log for skipped tracks
                        print(f"[SoundCloud Search Debug] Skipping entry {entry_index} ('{entry.get('title')}') due to duration: {duration_seconds}s (Range: {MIN_SONG_DURATION}-{MAX_SONG_DURATION})")
                        continue # Skip if duration is missing or outside the range

                    # SoundCloud often has cleaner titles, but let's try extraction anyway
                    # 'uploader' seems more reliable for artist on SoundCloud via yt-dlp
                    raw_title = entry.get('title', 'Unknown Title')
                    # Basic check: if " - " is present, use that, otherwise keep raw title and use uploader
                    if ' - ' in raw_title:
                         parts = raw_title.split(' - ', 1)
                         title = parts[1].strip() # Assume second part is title
                         artist = parts[0].strip() # Assume first part is artist
                    else:
                         title = raw_title
                         artist = entry.get('uploader', 'Unknown Artist')

                    # Fallback if title/artist extraction yields poor results
                    if not title or title == "Unknown Title":
                        title = raw_title
                    if not artist or artist == "Unknown Artist":
                        artist = entry.get('uploader', 'Unknown Artist')

                    results.append({
                        'title': title,
                        'channel': artist.strip(), # Use 'channel' key for consistency
                        'url': entry.get('webpage_url', entry.get('url', '')), # Prefer webpage_url if available
                        'duration': duration_seconds,
                        'source': 'soundcloud' # Add source identifier
                    })
                else:
                    # –õ–æ–≥, –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –ø—É—Å—Ç–∞—è
                    print(f"[SoundCloud Search Debug] Entry at index {entry_index} is None or empty.")
            print(f"[SoundCloud Search Debug] Processed {len(results)} valid entries.") # –õ–æ–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤
            return results
    except Exception as e:
        # –î–æ–±–∞–≤–∏–º –≤—ã–≤–æ–¥ traceback –¥–ª—è –±–æ–ª—å—à–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—à–∏–±–∫–µ
        print(f"An error occurred during SoundCloud search: {e}\n{traceback.format_exc()}")
        return []

async def search_bandcamp(query, max_results=50):
    """Searches Bandcamp using yt-dlp.
    Note: yt-dlp's bandcamp search (`bcsearch:`) primarily finds tracks, 
    but may not always provide accurate artist info directly in search results.
    It might return album artist instead of track artist sometimes.
    """
    try:
        # Use bcsearch for Bandcamp
        search_opts = {
            **ydl_opts,
            'default_search': 'bcsearch',
            'max_downloads': max_results,
            'extract_flat': True,
        }

        with yt_dlp.YoutubeDL(search_opts) as ydl:
            print(f"[Bandcamp Search Debug] Querying: bcsearch{max_results}:{query}")
            info = None # Initialize info
            try:
                info = ydl.extract_info(f"bcsearch{max_results}:{query}", download=False)
            except Exception as e:
                # Catch the specific "Unsupported url scheme" error for bcsearch
                if "Unsupported url scheme" in str(e) and "bcsearch" in str(e):
                    print(f"[Bandcamp Search] Warning: yt-dlp failed due to unsupported 'bcsearch' scheme. Skipping Bandcamp. Error: {e}")
                    return [] # Return empty list to skip this source
                else:
                    # Re-raise other unexpected errors or handle them generally
                    print(f"[Bandcamp Search] An unexpected error occurred during extract_info: {e}\n{traceback.format_exc()}")
                    return [] # Return empty list on other errors too
            
            print(f"[Bandcamp Search Debug] Raw info received: {info}") 
            
            if not info or 'entries' not in info:
                print("[Bandcamp Search Debug] No info or entries found in response.")
                return []

            print(f"[Bandcamp Search Debug] Found {len(info['entries'])} potential entries.")
            results = []
            for entry_index, entry in enumerate(info['entries']):
                if entry:
                    # Bandcamp often provides duration directly in seconds
                    duration = entry.get('duration') 
                    if not duration or not (MIN_SONG_DURATION <= duration <= MAX_SONG_DURATION):
                        print(f"[Bandcamp Search Debug] Skipping entry {entry_index} ('{entry.get('title')}') due to duration: {duration}s (Range: {MIN_SONG_DURATION}-{MAX_SONG_DURATION})")
                        continue
                        
                    # Title/Artist extraction for Bandcamp can be tricky via search
                    title = entry.get('title', 'Unknown Title')
                    # 'artist' field might be album artist, 'uploader' might be label
                    artist = entry.get('artist', entry.get('uploader', 'Unknown Artist')) 
                    
                    # Sometimes title includes artist "Artist - Track Title"
                    if ' - ' in title and not entry.get('artist'): # Check if artist wasn't already found
                        parts = title.split(' - ', 1)
                        potential_artist = parts[0].strip()
                        potential_title = parts[1].strip()
                        # Heuristic: if first part is shorter or looks like an artist name, assume it is
                        if len(potential_artist) < 30 and len(potential_artist) < len(potential_title):
                             artist = potential_artist
                             title = potential_title
                             
                    # Ensure title doesn't start with artist if already captured
                    if artist != 'Unknown Artist' and title.startswith(f"{artist} - "):
                         title = title[len(artist) + 3:]
                         
                    results.append({
                        'title': title.strip(),
                        'channel': artist.strip(), # Use 'channel' key for consistency
                        'url': entry.get('url', ''),
                        'duration': duration,
                        'source': 'bandcamp'
                    })
                else:
                    print(f"[Bandcamp Search Debug] Entry at index {entry_index} is None or empty.")
            print(f"[Bandcamp Search Debug] Processed {len(results)} valid entries.")
            return results
    except Exception as e:
        print(f"An error occurred during Bandcamp search: {e}\n{traceback.format_exc()}")
        return []

async def search_spotify(query, max_results=50):
    """Searches Spotify using spotdl and returns potential matches with download URLs."""
    if not (SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET):
        print("[Spotify Search] Error: Spotify credentials not configured.")
        return []

    loop = asyncio.get_running_loop()
    results = []
    
    try:
        print(f"[Spotify Search] Initializing Spotdl client for query: '{query}'")
        spotdl_client = Spotdl(
            client_id=SPOTIFY_CLIENT_ID, 
            client_secret=SPOTIFY_CLIENT_SECRET, 
            headless=True
        )

        # Search using the query string (blocking operation)
        # We assume spotdl search handles text query and might return more than max_results.
        # We will rely on asyncio.gather structure and MAX_TRACKS limit later.
        print(f"[Spotify Search] Querying spotdl search API for: '{query}'")
        
        # --- ADDED: Isolate spotdl search call with try/except and logging ---
        songs_list = [] # Default to empty list
        try:
             print(f"[Spotify Search DEBUG] Entering run_in_executor for spotdl_client.search...")
             # --- ADDED: Timeout for spotdl search ---
             songs_list = await asyncio.wait_for(
                 loop.run_in_executor(None, spotdl_client.search, [query]), 
                 timeout=20.0 # Set timeout to 20 seconds
             )
             # ----------------------------------------
             print(f"[Spotify Search DEBUG] Exited run_in_executor for spotdl_client.search.")
        except asyncio.TimeoutError:
             print(f"[Spotify Search WARNING] spotdl_client.search timed out after 20 seconds for query: '{query}'")
             # Return empty list on timeout
             return []
        except Exception as spotdl_search_err:
             print(f"[Spotify Search CRITICAL] Error DURING spotdl_client.search execution: {spotdl_search_err}")
             print(traceback.format_exc()) # Print full traceback for this specific error
             # Return empty list immediately if the search itself failed
             return []
        # ---------------------------------------------------------------------
            
        print(f"[Spotify Search] Found {len(songs_list)} potential matches from spotdl.")
        # --- ADDED DEBUG LOG: Print raw songs_list ---
        # print(f"[Spotify Search DEBUG] Raw songs_list: {songs_list}") 
        # Limit log size if too long
        songs_list_repr = repr(songs_list)
        if len(songs_list_repr) > 1500: # Limit log output size
             print(f"[Spotify Search DEBUG] Raw songs_list (first 1500 chars): {songs_list_repr[:1500]}...")
        else:
             print(f"[Spotify Search DEBUG] Raw songs_list: {songs_list_repr}")
        # -------------------------------------------

        processed_count = 0
        for index, song_obj in enumerate(songs_list):
            # Limit results processed from this source if needed (using max_results as a guide)
            if processed_count >= max_results:
                print(f"[Spotify Search] Reached max_results ({max_results}), stopping processing for this source.")
                break
                
            try:
                # --- ADDED DEBUG LOG: Print song object attributes ---
                s_name = getattr(song_obj, 'name', 'N/A')
                s_artists = getattr(song_obj, 'artists', [])
                s_artist = s_artists[0] if s_artists else 'N/A'
                s_url = getattr(song_obj, 'url', 'N/A')
                s_download_url = getattr(song_obj, 'download_url', None)
                print(f"[Spotify Search DEBUG {index}] Processing: Name='{s_name}', Artist='{s_artist}', URL='{s_url}', DownloadURL='{s_download_url}'")
                # ----------------------------------------------------
                
                title = song_obj.name
                artist = song_obj.artists[0] if song_obj.artists else "Unknown Artist"
                download_url = s_download_url # Use the already fetched attribute
                spotify_url = s_url # Use the already fetched attribute
                duration = getattr(song_obj, 'duration', 0) # Duration in ms from spotdl? Convert to s.
                duration_seconds = duration / 1000 if duration else 0

                if not download_url:
                    print(f"[Spotify Search] Skipping '{title} - {artist}' (URL: {spotify_url}) - No download_url found by spotdl.")
                    continue
                
                # Basic validation
                if not title or not artist:
                     print(f"[Spotify Search] Skipping track with missing title/artist. Data: {song_obj}")
                     continue
                     
                # Add to results
                results.append({
                    'title': title,
                    'channel': artist,
                    'url': download_url, # The URL found by spotdl (e.g., YouTube)
                    'duration': int(duration_seconds), # Store as integer seconds
                    'source': 'spotify'
                })
                processed_count += 1

            except Exception as parse_err:
                print(f"[Spotify Search] Error processing individual spotdl song object: {parse_err}. Data: {song_obj}")
                continue # Skip this song
                
        print(f"[Spotify Search] Processed {processed_count} valid tracks with download URLs.")
        return results

    except Exception as e:
        print(f"[Spotify Search] Error during spotdl search for query '{query}': {e}")
        print(traceback.format_exc())
        return []

def create_tracks_keyboard(tracks, page=0, search_id=""):
    total_pages = math.ceil(len(tracks) / TRACKS_PER_PAGE)
    start_idx = page * TRACKS_PER_PAGE
    end_idx = min(start_idx + TRACKS_PER_PAGE, len(tracks))
    
    buttons = []
    
    for i in range(start_idx, end_idx):
        track = tracks[i]
        track_data = {
            "title": track['title'],
            "artist": track['channel'],
            "url": track['url'],
            "search_id": search_id,
            # Ensure source is included if available, default to ''
            "source": track.get('source', '') 
        }
        
        track_json = json.dumps(track_data, ensure_ascii=False)
        if len(track_json.encode('utf-8')) > 60:
            callback_data = f"dl_{i+1}_{search_id}"
        else:
            callback_data = f"d_{base64.b64encode(track_json.encode('utf-8')).decode('utf-8')}"
        
        duration = track.get('duration', 0)
        if duration > 0:
            minutes = int(duration // 60)
            seconds = int(duration % 60)
            duration_str = f" ({minutes}:{seconds:02d})"
        else:
            duration_str = ""
        
        # Add source indicator to text
        source_indicator = ""
        if track.get('source') == 'youtube':
            source_indicator = " [YT]"
        elif track.get('source') == 'soundcloud':
            source_indicator = " [SC]"
        elif track.get('source') == 'bandcamp': # Added bandcamp indicator
             source_indicator = " [BC]"
        elif track.get('source') == 'spotify': # Added spotify indicator
             source_indicator = " [SP]"
        
        buttons.append([
            InlineKeyboardButton(
                text=f"üéß {track['title']} - {track['channel']}{duration_str}{source_indicator}", # Appended indicator
                callback_data=callback_data
            )
        ])
    
    if total_pages > 1:
        nav_buttons = []
        if page > 0:
            nav_buttons.append(
                InlineKeyboardButton(
                    text="‚¨ÖÔ∏è",
                    callback_data=f"page_{page-1}_{search_id}"
                )
            )
        nav_buttons.append(
            InlineKeyboardButton(
                text=f"{page+1}/{total_pages}",
                callback_data="info"
            )
        )
        if page < total_pages - 1:
            nav_buttons.append(
                InlineKeyboardButton(
                    text="‚û°Ô∏è",
                    callback_data=f"page_{page+1}_{search_id}"
                )
            )
        buttons.append(nav_buttons)
    
    return InlineKeyboardMarkup(inline_keyboard=buttons)

async def process_download_queue(user_id):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–≥—Ä—É–∑–æ–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    while download_queues[user_id] and len(download_tasks[user_id]) < MAX_PARALLEL_DOWNLOADS:
        queue_item = download_queues[user_id].pop(0)
        
        # Unpack queue item - could be (track_data, message) or (track_data, playlist_id)
        playlist_download_id = None
        if isinstance(queue_item, tuple) and len(queue_item) == 2:
             track_data, second_item = queue_item
             if isinstance(second_item, str): # Assuming playlist_id is a string UUID
                 playlist_download_id = second_item
             # else: # Old format, second_item is callback_message (handle if needed?)
             #    This part is tricky. The old code appended (track_data, callback.message)
             #    The new playlist code appends (track_data, playlist_download_id)
             #    We need download_track to accept playlist_id OR the message.
             #    Let's adjust the structure slightly. Always pass playlist_id (can be None).
             #    Let's assume for now queue items from search are handled differently
             #    and only URL downloads populate the queue this way.
             #    REVISIT: How search downloads (`process_download_callback*`) interact queue/tasks.
             #    For now, focus on playlist download flow initiated from URL.
        else:
             print(f"[Queue Processing] Error: Unexpected item format in queue for user {user_id}: {queue_item}")
             continue # Skip malformed item

        # If it's part of a playlist, update its status in the tracker
        if playlist_download_id and playlist_download_id in playlist_downloads:
             playlist_entry = playlist_downloads[playlist_download_id]
             found_track = False
             for track in playlist_entry['tracks']:
                 if track['url'] == track_data['url'] and track['status'] == 'pending':
                     track['status'] = 'downloading'
                     found_track = True
                     print(f"[Queue Processing] Set track {track_data['url']} in playlist {playlist_download_id} to 'downloading'.")
                     break
             if not found_track:
                 print(f"[Queue Processing] Warning: Could not find pending track {track_data['url']} in playlist {playlist_download_id} to set as 'downloading'.")
                 # Maybe already picked up? Continue processing anyway.

        # --- Task Creation ---
        # Need to decide what context to pass to download_track.
        # For playlists, it needs playlist_id.
        # For single URL downloads (if they use this queue?), maybe the status_message?
        # Let's pass track_data and playlist_id (which can be None).
        # download_track will need access to playlist_downloads if id is not None.
        
        # Ensure user_id exists in download_tasks
        if user_id not in download_tasks: download_tasks[user_id] = {}

        # Check if already downloading THIS EXACT URL (unlikely due to queue pop, but safe)
        if track_data["url"] in download_tasks[user_id]:
             print(f"[Queue Processing] Warning: Task for URL {track_data['url']} already exists for user {user_id}. Skipping queue item.")
             continue

        print(f"[Queue Processing] Creating download task for: {track_data['title']} (Playlist ID: {playlist_download_id})")
        task = asyncio.create_task(
            # Pass playlist_id to download_track
            download_track(user_id, track_data, playlist_download_id=playlist_download_id)
        )
        download_tasks[user_id][track_data["url"]] = task

def _blocking_download_and_convert(url, download_opts):
    """Helper function to run blocking yt-dlp download and return info dict."""
    with yt_dlp.YoutubeDL(download_opts) as ydl:
        # Use extract_info with download=True to get info dict with filepath
        info_dict = ydl.extract_info(url, download=True)
        return info_dict

# Adjust download_track signature and logic
async def download_track(user_id, track_data, callback_message=None, status_message=None, original_message_context=None, playlist_download_id=None):
    """Downloads a single track. If part of a playlist (playlist_download_id is set),
    it updates the central playlist tracker instead of sending the file directly."""
    
    # Compatibility: Handle older calls that might still pass messages
    # If playlist_download_id is provided, message arguments are ignored for status updates.
    # If playlist_download_id is None, we expect callback_message and status_message for single downloads.
    
    temp_path = None # Initialize temp_path to prevent NameError in finally
    loop = asyncio.get_running_loop()
    is_playlist_track = playlist_download_id is not None
    
    # --- Get necessary info from playlist tracker if applicable ---
    playlist_entry = None
    original_status_message_id = None
    chat_id_for_updates = None

    if is_playlist_track:
        if playlist_download_id in playlist_downloads:
            playlist_entry = playlist_downloads[playlist_download_id]
            original_status_message_id = playlist_entry.get('status_message_id')
            chat_id_for_updates = playlist_entry.get('chat_id')
        else:
            # This shouldn't happen if queuing logic is correct
            print(f"ERROR: download_track called with playlist_id {playlist_download_id} but entry not found!")
            # Clean up task tracking and exit? Or try to proceed as single?
            # Let's log error and exit the task gracefully.
            if user_id in download_tasks:
                download_tasks[user_id].pop(track_data["url"], None)
                if not download_tasks[user_id]: del download_tasks[user_id]
            return # Exit task

    elif callback_message and status_message:
        # Use message context for single downloads
        chat_id_for_updates = callback_message.chat.id
        original_status_message_id = status_message.message_id
    else:
        # This case should ideally not happen for single downloads either if triggered correctly
        # Check if original_message_context was provided as a fallback (e.g., direct URL download case?)
        if original_message_context:
             chat_id_for_updates = original_message_context.chat.id
             # We don't have a status_message_id in this specific fallback path
             original_status_message_id = None 
             print(f"Warning: download_track using original_message_context for single track, no status_message.")
        else:
            print(f"ERROR: download_track called for single track (playlist_id=None) but missing message context (callback/status messages and original_message_context)!")
            # Clean up task tracking and exit
            if user_id in download_tasks:
                download_tasks[user_id].pop(track_data["url"], None)
                if not download_tasks[user_id]: del download_tasks[user_id]
            return # Exit task
    # Initialize variables for track info
    try:
        title = track_data["title"]
        artist = track_data["channel"] # Changed key internally, was 'artist' in playlist prep
        url = track_data["url"]
    except KeyError as e:
        print(f"ERROR: Missing required track data field: {e}")
        # Clean up task tracking and exit
        if user_id in download_tasks:
            download_tasks[user_id].pop(track_data["url"], None) 
            if not download_tasks[user_id]: del download_tasks[user_id]
        return # Exit task
        # –°–æ–∑–¥–∞–µ–º –ë–û–õ–ï–ï –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ _, —É–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –±—É–∫–≤/—Ü–∏—Ñ—Ä/./_/- 
        safe_title = "".join(c if c.isalnum() or c in ('.', '_', '-') else '_' for c in title).strip('_').strip('.').strip('-')
        # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        safe_title = safe_title[:100] 
        if not safe_title:
             safe_title = f"audio_{uuid.uuid4()}" # Fallback name

        temp_dir = tempfile.gettempdir() # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å /tmp –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
        
        # --- Generate Unique Base Path ---
        if is_playlist_track:
            base_temp_path = os.path.join(temp_dir, f"pl_{playlist_download_id}_{safe_title}")
        else:
            task_uuid = str(uuid.uuid4()) # Unique ID for this single download task
            base_temp_path = os.path.join(temp_dir, f"single_{task_uuid}_{safe_title}")
        print(f"[Download Path] Base temp path set to: {base_temp_path}")
        # ---------------------------------
        
        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ –ø–µ—Ä–µ–¥ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ–º
        # (This check might be less critical now with unique names, but kept for safety)
        for ext in ['.mp3', '.m4a', '.webm', '.mp4', '.opus', '.ogg', '.aac', '.part']:
            potential_path = f"{base_temp_path}{ext}"
            if os.path.exists(potential_path):
                try:
                    os.remove(potential_path)
                    print(f"Removed existing file: {potential_path}")
                except OSError as e:
                    print(f"Warning: Could not remove existing file {potential_path}: {e}")
        
        # --- Download Options setup ---
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º ydl_opts –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        download_opts = {
            'format': 'bestaudio[ext=m4a]/bestaudio/best', # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º m4a –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            # –í–ê–ñ–ù–û: outtmpl –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .%(ext)s 
            # —á—Ç–æ–±—ã ytdl —Å–∞–º –æ–±—Ä–∞–±–æ—Ç–∞–ª –∏–º—è –¥–æ –∏ –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            'outtmpl': base_temp_path + '.%(ext)s', 
            'quiet': True, # Keep quiet for track download
            'verbose': False, # Keep quiet for track download
            'no_warnings': True, # Keep quiet for track download
            'prefer_ffmpeg': True,
            'nocheckcertificate': True,
            'ignoreerrors': True, # –û—Å—Ç–∞–≤–ª—è–µ–º, –Ω–æ –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
            'extract_flat': False, # –ù—É–∂–Ω–æ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            'ffmpeg_location': '/usr/bin/ffmpeg' # –û—Å—Ç–∞–≤–ª—è–µ–º —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –ø—É—Ç–∏
        }
        
        expected_mp3_path = base_temp_path + '.mp3'

        # --- Blocking Download call --- 
        # (Removed the pre-download status update call that caused AttributeError)
        print(f"\nStarting download for: {title} - {artist}")
        # print(f"URL: {url}") # Debug
        # print(f"Output template: {download_opts['outtmpl']}") # Debug
        # print(f"Expected MP3 path: {expected_mp3_path}") # Debug
        # print(f"Using download options: {download_opts}") # Debug

            # –ó–∞–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏—Ä—É—é—â—É—é –∑–∞–≥—Ä—É–∑–∫—É/–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        await loop.run_in_executor(
            None, 
                _blocking_download_and_convert,
                url,
                download_opts # –ü–µ—Ä–µ–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ download_opts
            )
            
        print(f"Finished blocking download call for: {title} - {artist}")

            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è --- 
        if not os.path.exists(expected_mp3_path):
                print(f"ERROR: Expected MP3 file NOT FOUND at {expected_mp3_path} after download attempt.")
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º, –Ω–µ –æ—Å—Ç–∞–ª—Å—è –ª–∏ —Ñ–∞–π–ª —Å –¥—Ä—É–≥–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º (–æ—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏?)
                found_other = False
                for ext in ['.m4a', '.webm', '.opus', '.ogg', '.aac']:
                     potential_path = f"{base_temp_path}{ext}"
                     if os.path.exists(potential_path):
                         print(f"Warning: Found intermediate file {potential_path} instead of MP3. Conversion likely failed.")
                         found_other = True
                         # –ü–æ–ø—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª
                         try: 
                             os.remove(potential_path)
                         except OSError as e:
                             print(f"Could not remove intermediate file {potential_path}: {e}")
                         break
        raise Exception(f"—Ñ–∞–π–ª {expected_mp3_path} –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
            
        temp_path = expected_mp3_path 
        print(f"Confirmed MP3 file exists at: {temp_path}")
            
        if os.path.getsize(temp_path) == 0:
                print(f"ERROR: Downloaded file {temp_path} is empty.")
        raise Exception("—Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π —á–µ—Ç –Ω–µ —Ç–æ")
            
        print(f"File size: {os.path.getsize(temp_path)} bytes")

            # --- NEW: Validate MP3 file structure ---
        try:
                print(f"Validating MP3 structure for {temp_path}...")
                audio_check = MP3(temp_path) 
                if not audio_check.info.length > 0:
                     print(f"ERROR: MP3 file {temp_path} loaded but has zero length/duration.")
                raise Exception("—Ñ–∞–π–ª mp3 —Å–∫–∞—á–∞–ª—Å—è –Ω–æ –ø–æ—Ö–æ–∂–µ –±–∏—Ç—ã–π (–Ω—É–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞)")
                print(f"MP3 Validation PASSED for {temp_path}, duration: {audio_check.info.length}s")
        except Exception as validation_error:
                print(f"ERROR: MP3 Validation FAILED for {temp_path}: {validation_error}")
        raise Exception(f"—Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º mp3 {validation_error}")

        # --- Processing based on whether it's a playlist track --- 
        if is_playlist_track:
            print(f"[Playlist Download] Track '{title}' SUCCESS. Storing path: {temp_path}")
            # Update playlist tracker
            track_updated = False
            for track in playlist_entry['tracks']:
                if track['url'] == url:
                    track['status'] = 'success'
                    track['file_path'] = temp_path
                    track_updated = True
                    break
            
            if not track_updated:
                 print(f"ERROR: Could not find track {url} in playlist {playlist_download_id} tracker to mark success.")
                 # Don't delete file yet, maybe send_completed_playlist can find it?
                 
            playlist_entry['completed_tracks'] += 1
            
            # --- Update Progress Message ---
            completed = playlist_entry['completed_tracks']
            total = playlist_entry['total_tracks']
            playlist_title_for_status = playlist_entry.get('playlist_title', '')
            if original_status_message_id and chat_id_for_updates and completed < total:
                try:
                    # Avoid updating on the very last track, as send_completed_playlist will handle the final message
                    status_text = f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–ª–µ–π–ª–∏—Å—Ç–∞ '{playlist_title_for_status}': {completed}/{total}"
                    await bot.edit_message_text(
                        status_text,
                        chat_id=chat_id_for_updates,
                        message_id=original_status_message_id
                    )
                except Exception as prog_upd_err:
                    print(f"[Playlist Progress] Warning: Failed to update progress message {original_status_message_id}: {prog_upd_err}")
                # ------------------------------

            # Check if playlist is complete
            if completed >= total: # Use >= for safety
                 print(f"Playlist {playlist_download_id} ('{playlist_entry['playlist_title']}') completed. Triggering send function.")
                 asyncio.create_task(send_completed_playlist(playlist_download_id))
                 # Keep temp_path, send_completed_playlist will handle cleanup
            else:
                 print(f"Playlist {playlist_download_id} progress: {playlist_entry['completed_tracks']}/{playlist_entry['total_tracks']}")
                 # Keep temp_path for later sending
                 
            # DO NOT SEND OR DELETE TEMP FILE HERE FOR PLAYLISTS

        else: # --- Single track download: Send immediately ---
            print(f"Setting metadata for {temp_path}...")
            if set_mp3_metadata(temp_path, title, artist):
                print(f"Metadata set successfully. Preparing to send {temp_path}.")
                # Delete original status message only for single downloads
                if original_status_message_id and chat_id_for_updates:
                    try:
                        await bot.delete_message(chat_id=chat_id_for_updates, message_id=original_status_message_id)
                    except Exception as del_err:
                        print(f"Warning: Failed to delete original status message {original_status_message_id}: {del_err}")

                # Use callback_message context if available for sending confirmation
                sending_context = callback_message if callback_message else original_message_context # Fallback to original if needed
                sending_message = await sending_context.answer("üì§ –æ—Ç–ø—Ä–∞–≤–ª—è—é —Ç—Ä–µ–∫") # Use answer on the context

                print(f"Sending audio {temp_path}...")
                await bot.send_audio(
                    chat_id=chat_id_for_updates, # Use chat_id derived earlier
                    audio=FSInputFile(temp_path),
                    title=title,
                    performer=artist
                )
                print(f"Audio sent successfully. Deleting sending message.")
                await bot.delete_message(
                    chat_id=sending_message.chat.id, # Use chat_id from the message we just sent
                    message_id=sending_message.message_id
                )
                print(f"Finished processing track: {title} - {artist}")
            else:
                print(f"ERROR: Failed to set metadata for {temp_path}.")
                raise Exception(f"–æ—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {title} - {artist}")
             # Cleanup happens in finally block for single tracks too now

    except Exception as e:
         # More detailed error logging
         print(f"ERROR during download/processing for {title} - {artist}: {type(e).__name__} - {e}")
         print(traceback.format_exc()) # Print full traceback

         error_text = f"‚ùå –±–ª–∏–Ω –æ—à–∏–±–∫–∞ {str(e).lower()}"
         if len(error_text) > 4000: error_text = error_text[:3995] + "..."

         if is_playlist_track:
             # Update playlist tracker with failure
             track_updated = False
             # Ensure playlist_entry exists before iterating
             if playlist_entry:
                 for track in playlist_entry['tracks']:
                     if track['url'] == url:
                         track['status'] = 'failed'
                         track['error_message'] = str(e)
                         track_updated = True
                         break
                 if not track_updated:
                     print(f"ERROR: Could not find track {url} in playlist {playlist_download_id} tracker to mark failure.")

                 playlist_entry['completed_tracks'] += 1
                 print(f"Playlist {playlist_download_id} progress after failure: {playlist_entry['completed_tracks']}/{playlist_entry['total_tracks']}")

                 # --- Update Progress Message (also after failure) ---
                 completed = playlist_entry['completed_tracks']
                 total = playlist_entry['total_tracks']
                 playlist_title_for_status = playlist_entry.get('playlist_title', '')
                 if original_status_message_id and chat_id_for_updates and completed < total:
                     try:
                         status_text = f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–ª–µ–π–ª–∏—Å—Ç–∞ '{playlist_title_for_status}': {completed}/{total}"
                         await bot.edit_message_text(
                             status_text,
                             chat_id=chat_id_for_updates,
                             message_id=original_status_message_id
                         )
                     except Exception as prog_upd_err:
                         print(f"[Playlist Progress] Warning: Failed to update progress message {original_status_message_id}: {prog_upd_err}")
                 # -----------------------------------------------

                 # Check if playlist is complete even after failure
                 if completed >= total: # Use >= for safety
                     print(f"Playlist {playlist_download_id} ('{playlist_entry['playlist_title']}') completed (with failures). Triggering send function.")
                     asyncio.create_task(send_completed_playlist(playlist_download_id))
             else:
                 print(f"ERROR: Playlist entry {playlist_download_id} was None during exception handling for track {url}.")
             
             # Do not edit the main status message here for individual track failures

         else: # Single track failure - edit the status message or send a new one
             if original_status_message_id and chat_id_for_updates:
                 try:
                     await bot.edit_message_text(
                         chat_id=chat_id_for_updates,
                         message_id=original_status_message_id,
                         text=error_text
                     )
                 except Exception as edit_error:
                     print(f"Failed to edit status message for error: {edit_error}")
                     # Fallback: Try sending a new message using available context
                     try:
                         error_context = callback_message if callback_message else original_message_context # Use appropriate context
                         if error_context: # Check if context exists
                             await error_context.answer(error_text)
                         else:
                             print("[Single Download] Warning: No message context found to send error reply.")
                     except Exception as send_error: # Added except block for the inner try
                         print(f"[Single Download] Warning: Failed to send new message for error: {send_error}")
             else:
                # If we couldn't edit (e.g., no status_message_id), try sending a new message directly
                print(f"[Single Download] No status message to edit, attempting to send error as new message.")
                try:
                   error_context = callback_message if callback_message else original_message_context
                   if error_context:
                       await error_context.answer(error_text)
                   else:
                       print("[Single Download] Warning: No message context found to send error reply.")
                except Exception as send_error:
                   print(f"[Single Download] Warning: Failed to send new message for error: {send_error}")

    finally:
         # --- Cleanup ---
         # For single tracks, temp_path should be deleted.
         # For playlist tracks, temp_path should ONLY be deleted if the download FAILED.
         # Successful playlist tracks are deleted later by send_completed_playlist.
         should_delete_temp_file = False
         # Check temp_path exists and the file itself exists
         if temp_path and os.path.exists(temp_path):
             if not is_playlist_track:
                 # Always delete for single tracks (success or failure)
                 should_delete_temp_file = True
                 print(f"[Cleanup] Marking single track temp file for deletion: {temp_path}")
             else:
                 # For playlists, only delete if this track failed
                 track_failed = False
                 if playlist_entry: # Check playlist_entry exists
                     for track in playlist_entry['tracks']:
                         # Check status only if URL matches (should be unique within playlist)
                         if track['url'] == url:
                             if track['status'] == 'failed':
                                 track_failed = True
                             break # Found the track, no need to check further
                     if track_failed:
                         should_delete_temp_file = True
                         print(f"[Cleanup] Marking FAILED playlist track temp file for deletion: {temp_path}")
                     else:
                         print(f"[Cleanup] Keeping SUCCESSFUL playlist track temp file for later sending: {temp_path}")

             if should_delete_temp_file:
                 try:
                     print(f"Cleaning up temporary file: {temp_path}")
                     os.remove(temp_path)
                 except Exception as remove_error:
                     print(f"Warning: Failed to remove temp file {temp_path}: {remove_error}")
             
         # --- Task Management ---
         # Remove task entry regardless of playlist/single or success/failure, as the task itself is done.
         if user_id in download_tasks:
             if download_tasks[user_id].pop(track_data["url"], None):
                  print(f"Removed task entry for URL: {track_data['url']}")
             else:
                  print(f"Task entry for URL {track_data['url']} not found or already removed.")
             if not download_tasks[user_id]:
                 print(f"No tasks left for user {user_id}, removing user entry.")
                 del download_tasks[user_id]
             else:
                  print(f"{len(download_tasks[user_id])} tasks remaining for user {user_id}.")

         # --- Trigger Queue Processing ---
         # Check queue AGAIN after finishing a task, regardless of type.
         # This ensures the next item is picked up if slots are free.
         if user_id in download_queues and download_queues[user_id]: 
             # Check if parallel slots are available before triggering
             active_downloads = sum(1 for task in download_tasks.get(user_id, {}).values() if not task.done())
             if active_downloads < MAX_PARALLEL_DOWNLOADS:
                  print(f"Processing next item in queue for user {user_id} (active: {active_downloads}).")
                  # Use create_task to avoid blocking the finally block
                  asyncio.create_task(process_download_queue(user_id))
             else:
                  print(f"Queue for user {user_id} has items, but max parallel downloads ({active_downloads}) reached.")
         # else: No need for an else print here, common case

# --- Function to send completed playlist tracks ---
async def send_completed_playlist(playlist_download_id):
    """Sends all successfully downloaded tracks for a completed playlist in order,
    then cleans up."""
    playlist_entry = playlist_downloads.pop(playlist_download_id, None)
    if not playlist_entry:
        print(f"[Send Playlist] ERROR: Playlist entry {playlist_download_id} not found. Cannot send.")
        return

    user_id = playlist_entry['user_id']
    chat_id = playlist_entry['chat_id']
    original_status_message_id = playlist_entry.get('status_message_id')
    playlist_title = playlist_entry.get('playlist_title', '–ü–ª–µ–π–ª–∏—Å—Ç')
    tracks = playlist_entry.get('tracks', [])
    
    successful_tracks = [t for t in tracks if t['status'] == 'success' and t.get('file_path')]
    failed_tracks = [t for t in tracks if t['status'] == 'failed']
    
    # --- Update Status Message or Send New One ---
    final_status_message = None
    final_status_text = f"‚úÖ –ü–ª–µ–π–ª–∏—Å—Ç '{playlist_title}' —Å–∫–∞—á–∞–Ω. –û—Ç–ø—Ä–∞–≤–ª—è—é {len(successful_tracks)} —Ç—Ä–µ–∫–æ–≤..."
    if len(failed_tracks) > 0:
        final_status_text += f" (–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {len(failed_tracks)})"
    
    try:
        if original_status_message_id:
            await bot.edit_message_text(
                chat_id=chat_id,
                message_id=original_status_message_id,
                text=final_status_text
            )
            # Store the message object if needed later, though we might delete it soon
            # For simplicity, let's assume editing is enough for now.
        else:
            # If original status message ID was lost, send a new one
            final_status_message = await bot.send_message(chat_id, final_status_text)
            # Store its ID in the (now popped) entry? Not straightforward.
            # Let's just send it and potentially delete later if we can get the ID.
    except Exception as e:
        print(f"[Send Playlist] Warning: Failed to update/send final status message for {playlist_download_id}: {e}")
        # Try sending a new message as a fallback
        try:
            final_status_message = await bot.send_message(chat_id, final_status_text)
        except Exception as send_err:
            print(f"[Send Playlist] Error: Could not send final status message either: {send_err}")
            # Proceed with sending tracks anyway if possible

    # --- Send Successful Tracks in Order ---
    sent_count = 0
    send_errors = 0
    files_to_delete = []

    # Add failed track files to cleanup list immediately
    for track in failed_tracks:
        if track.get('file_path') and os.path.exists(track['file_path']):
            files_to_delete.append(track['file_path'])

    # Iterate through original track list to maintain order
    for track in tracks:
        if track['status'] == 'success' and track.get('file_path'):
            file_path = track['file_path']
            title = track.get('title', 'Unknown Title')
            artist = track.get('artist', 'Unknown Artist')
            
            if os.path.exists(file_path):
                try:
                    print(f"[Send Playlist] Sending track {track['original_index']}: {title} from {file_path}")
                    # Setting metadata again just before sending (optional, but maybe safer)
                    set_mp3_metadata(file_path, title, artist)
                    
                    await bot.send_audio(
                        chat_id=chat_id,
                        audio=FSInputFile(file_path),
                        title=title,
                        performer=artist
                    )
                    sent_count += 1
                    files_to_delete.append(file_path) # Add successfully sent file for deletion
                    # Small delay between sends? Optional.
                    # await asyncio.sleep(0.5)
                except Exception as send_audio_err:
                    print(f"[Send Playlist] ERROR sending track {title} ({file_path}): {send_audio_err}")
                    send_errors += 1
                    # Keep file for now? Or add to delete list anyway?
                    # Let's add to delete list, as we can't send it.
                    files_to_delete.append(file_path)
            else:
                print(f"[Send Playlist] ERROR: File path {file_path} for track {title} not found!")
                send_errors += 1

    # --- Final Cleanup and Summary ---
    print(f"[Send Playlist] Finished sending for {playlist_download_id}. Sent: {sent_count}, Failed to send: {send_errors}, Failed to download: {len(failed_tracks)}")

    # Delete temporary files
    deleted_count = 0
    for f_path in set(files_to_delete): # Use set to avoid duplicates
        try:
            if os.path.exists(f_path):
                os.remove(f_path)
                deleted_count += 1
        except Exception as del_err:
            print(f"[Send Playlist] Warning: Failed to delete temp file {f_path}: {del_err}")
    print(f"[Send Playlist] Cleaned up {deleted_count} temporary files for {playlist_download_id}.")

    # Optionally send a final summary message if needed, or delete the status message
    try:
        # Delete the status message ("–û—Ç–ø—Ä–∞–≤–ª—è—é X —Ç—Ä–µ–∫–æ–≤...")
        status_message_to_delete_id = final_status_message.message_id if final_status_message else original_status_message_id
        if status_message_to_delete_id:
            await bot.delete_message(chat_id=chat_id, message_id=status_message_to_delete_id)
            print(f"[Send Playlist] Deleted final status message {status_message_to_delete_id}")
    except Exception as final_del_err:
        print(f"[Send Playlist] Warning: Failed to delete final status message: {final_del_err}")

    # Playlist entry already removed from playlist_downloads at the start

def set_mp3_metadata(file_path, title, artist):
    try:
        try:
            audio = ID3(file_path)
        except:
            audio = ID3()
        
        audio["TIT2"] = TIT2(encoding=3, text=title)
        audio["TPE1"] = TPE1(encoding=3, text=artist)
        audio.save(file_path)
        return True
    except Exception as e:
        print(f"–æ—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        return False

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer(
        "üêà‚Äç‚¨õ –ø—Ä–∏–≤–µ—Ç–∏–∫ —è\n\n"
        "‚úÖ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π\n"
        "‚úÖ –∏–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π\n"
        "‚úÖ —Å–∫–∞—á–∏–≤–∞—é—â–∏–π\n"
        "‚úÖ —é–Ω—ã–π\n"
        "‚úÖ –Ω–æ–≤–æ–±—Ä–∞–Ω–µ—Ü\n\n"
        "üéµ –∏—â—É –∏ —Å–∫–∞—á–∏–≤–∞—é –º—É–∑—ã–∫—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é\n"
        "üîó –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–∫–∏–Ω—å –º–Ω–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ –∏ —è –ø–æ–ø—Ä–æ–±—É—é —Å–∫–∞—á–∞—Ç—å\n\n"
        "üë• —Ç–∞–∫–∂–µ –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–∏—Ç—å –±–æ—Ç–∞ –≤ –≥—Ä—É–ø–ø—É –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É\n"
        "¬´–º—É–∑—ã–∫–∞ (–∑–∞–ø—Ä–æ—Å)¬ª\n"
        "–ª–∏–±–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ —Ç–∞–º"
    )

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    # Using triple quotes for cleaner multiline string
    help_text = """*–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ—Ç–æ–º* 

1Ô∏è‚É£ **–ø–æ–∏—Å–∫ –º—É–∑—ã–∫–∏** –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞ –∏–ª–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è —è –ø–æ–∏—â—É –Ω–∞ soundcloud bandcamp –∏ youtube –∏ –ø–æ–∫–∞–∂—É —Å–ø–∏—Å–æ–∫

2Ô∏è‚É£ **—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ —Å—Å—ã–ª–∫–µ** –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –≤–∏–¥–µ–æ –∏–ª–∏ –∞—É–¥–∏–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä —Å youtube soundcloud vk insta tiktok –∏ –º–Ω–æ–≥–∏—Ö –¥—Ä—É–≥–∏—Ö) —è –ø–æ–ø—ã—Ç–∞—é—Å—å —Å–∫–∞—á–∞—Ç—å –º–µ–¥–∏–∞

*–∫–æ–º–∞–Ω–¥—ã*
/start - –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
/search [–∑–∞–ø—Ä–æ—Å] - –∏—Å–∫–∞—Ç—å –º—É–∑—ã–∫—É –ø–æ –∑–∞–ø—Ä–æ—Å—É
/cancel - –æ—Ç–º–µ–Ω–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–≥—Ä—É–∑–∫–∏ (–∏–∑ –ø–æ–∏—Å–∫–∞)"""
    await message.answer(help_text, parse_mode="Markdown")

@dp.message(Command("search"))
async def cmd_search(message: types.Message):
    if len(message.text.split()) < 2:
        await message.answer("‚ùå –Ω–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ—Å–ª–µ /search –ø–ª–∏–∑\n–Ω–∞–ø—Ä–∏–º–µ—Ä /search coldplay yellow")
        return
    
    query = " ".join(message.text.split()[1:])
    searching_message = await message.answer("üîç –∏—â—É –º—É–∑—ã–∫—É...")
    
    search_id = str(uuid.uuid4())
    # Search all sources concurrently
    max_results_per_source = MAX_TRACKS // 4 # Divide budget among 4 sources now
    spotify_results, youtube_results, soundcloud_results, bandcamp_results = await asyncio.gather(
        search_spotify(query, max_results_per_source), # Added Spotify search
        search_youtube(query, max_results_per_source),
        search_soundcloud(query, max_results_per_source),
        search_bandcamp(query, max_results_per_source)
    )

    # Prioritize Spotify -> SoundCloud -> Bandcamp -> YouTube results
    combined_results = []
    # Add Spotify results first
    for sp_track in spotify_results:
         if 'source' not in sp_track: # Should have source already, but defensive check
             sp_track['source'] = 'spotify'
         combined_results.append(sp_track)
    # Add SoundCloud results
    for sc_track in soundcloud_results:
        if 'source' not in sc_track:
            sc_track['source'] = 'soundcloud'
        combined_results.append(sc_track)
    # Then add Bandcamp results
    for bc_track in bandcamp_results:
         if 'source' not in bc_track:
             bc_track['source'] = 'bandcamp'
         combined_results.append(bc_track)
    # Then add YouTube results
    for yt_track in youtube_results:
        if 'source' not in yt_track:
            yt_track['source'] = 'youtube'
        combined_results.append(yt_track)

    # Limit total results if needed (redundant if MAX_TRACKS was respected by sources?)
    # combined_results = combined_results[:MAX_TRACKS]

    if not combined_results:
        await message.answer("‚ùå —á–µ—Ç –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å") # Updated message
        await bot.delete_message(chat_id=searching_message.chat.id, message_id=searching_message.message_id)
        return
    
    search_results[search_id] = combined_results # Store combined results
    keyboard = create_tracks_keyboard(combined_results, 0, search_id)
    
    await message.answer(
        f"üéµ –Ω–∞—à–µ–ª –¥–ª—è —Ç–µ–±—è {len(combined_results)} —Ç—Ä–µ–∫–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É ¬´{query}¬ª ‚¨á",
        reply_markup=keyboard
    )
    await bot.delete_message(chat_id=searching_message.chat.id, message_id=searching_message.message_id)

@dp.message(Command("cancel"))
async def cmd_cancel(message: types.Message):
    user_id = message.from_user.id
    cancelled_tasks_count = 0
    cancelled_playlists_count = 0
    cleaned_files_count = 0
    active_tasks_urls = []

    # --- Cancel active download tasks --- 
    if user_id in download_tasks:
        # Get URLs of tasks to be cancelled for this user
        tasks_to_cancel = {
            url: task for url, task in download_tasks[user_id].items() 
            if task and not task.done() and not task.cancelled()
        }
        active_tasks_urls = list(tasks_to_cancel.keys())
        
        if tasks_to_cancel:
            print(f"[Cancel] Cancelling {len(tasks_to_cancel)} active tasks for user {user_id}.")
            for url, task in tasks_to_cancel.items():
                task.cancel()
                cancelled_tasks_count += 1
            # Give tasks a moment to cancel (important for file cleanup later)
            await asyncio.sleep(0.2)
            # Clean up cancelled/finished tasks from the user's entry
            download_tasks[user_id] = { 
                url: task for url, task in download_tasks[user_id].items() 
                if task and not task.cancelled() and not task.done() 
            }
        if not download_tasks[user_id]:
            del download_tasks[user_id]
        else:
            print(f"[Cancel] No active download tasks found for user {user_id} in download_tasks.")
            # If no active tasks, but entry exists, clear it
            if not download_tasks.get(user_id):
                del download_tasks[user_id]
        
    # --- Clear user's download queue --- 
    queued_items_count = 0 # Initialize count
    if user_id in download_queues:
        queued_items_count = len(download_queues[user_id])
    if queued_items_count > 0:
        print(f"[Cancel] Clearing {queued_items_count} items from queue for user {user_id}.")
        download_queues[user_id].clear()
        # Remove user entry if queue becomes empty (or was already empty)
        # Check if key exists before deleting
        if user_id in download_queues: # This check might be redundant after clear, but safe
            del download_queues[user_id]

    # --- Cancel and cleanup active playlist downloads --- 
    playlists_to_remove = []
    files_to_delete_from_playlists = []
    for pl_id, pl_entry in list(playlist_downloads.items()): # Iterate over a copy of items
        if pl_entry.get('user_id') == user_id:
            print(f"[Cancel] Found active playlist {pl_id} ('{pl_entry.get('playlist_title')}') for user {user_id}.")
            cancelled_playlists_count += 1
            playlists_to_remove.append(pl_id)
            
            # Mark associated active tasks (if any remaining after first step) as cancelled conceptually
            # And collect file paths for cleanup
            for track in pl_entry.get('tracks', []):
                # Check if this track's task was among those actively cancelled
                # Or if it was already completed but file exists
                task_is_active = track['url'] in active_tasks_urls
                file_exists = track.get('file_path') and os.path.exists(track['file_path'])
                
                if task_is_active or file_exists:
                    if file_exists:
                        files_to_delete_from_playlists.append(track['file_path'])
                        print(f"[Cancel] Marked playlist file for deletion: {track['file_path']}")
            
            # Try to delete the status message associated with this playlist
            status_msg_id = pl_entry.get('status_message_id')
            chat_id = pl_entry.get('chat_id')
            if status_msg_id and chat_id:
                try:
                    await bot.delete_message(chat_id=chat_id, message_id=status_msg_id)
                    print(f"[Cancel] Deleted status message {status_msg_id} for cancelled playlist {pl_id}.")
                except Exception as del_err:
                    print(f"[Cancel] Warning: Failed to delete status message {status_msg_id} for playlist {pl_id}: {del_err}")

    # Remove cancelled playlist entries from the main dictionary
    for pl_id in playlists_to_remove:
        if pl_id in playlist_downloads:
            del playlist_downloads[pl_id]
            print(f"[Cancel] Removed playlist entry {pl_id} from tracker.")

    # --- Perform File Cleanup --- 
    # This relies on tasks being given time to cancel above
    # Collect files associated with tasks that were *just* cancelled
    # Note: This might include files from single downloads too
    files_to_delete_from_tasks = []
    # Re-check download_tasks for potentially completed files of cancelled tasks (race condition?)
    # Let's assume the playlist check above is sufficient for playlist files.
    # Need a way to reliably find temp files for cancelled single-downloads.
    # This is hard because download_track cleans up its own failed files.
    # Let's focus cleanup on files explicitly collected from cancelled playlists.

    # Cleanup files collected from cancelled playlists
    for f_path in set(files_to_delete_from_playlists): # Use set for unique paths
        try:
            if os.path.exists(f_path):
                os.remove(f_path)
                cleaned_files_count += 1
                print(f"[Cancel Cleanup] Deleted: {f_path}")
        except Exception as rem_err:
            print(f"[Cancel Cleanup] Warning: Failed to remove {f_path}: {rem_err}")

    # --- Send Confirmation Message --- 
    if cancelled_tasks_count > 0 or cancelled_playlists_count > 0 or queued_items_count > 0:
        response_parts = ["‚úÖ –æ–∫"]
        if cancelled_tasks_count > 0:
            response_parts.append(f"–æ—Ç–º–µ–Ω–∏–ª {cancelled_tasks_count} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫")
        if cancelled_playlists_count > 0:
             response_parts.append(f"–æ—Å—Ç–∞–Ω–æ–≤–∏–ª {cancelled_playlists_count} –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤")
        if queued_items_count > 0:
            response_parts.append(f"–æ—á–∏—Å—Ç–∏–ª –æ—á–µ—Ä–µ–¥—å ({queued_items_count} —Ç—Ä–µ–∫–æ–≤)")
        if cleaned_files_count > 0:
             response_parts.append(f"—É–¥–∞–ª–∏–ª {cleaned_files_count} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
             
        final_response = " ".join(response_parts)
        # Ensure comma separation if multiple parts exist besides "‚úÖ –æ–∫"
        if len(response_parts) > 2:
             final_response = response_parts[0] + " " + ", ".join(response_parts[1:])
             
        await message.answer(final_response)
    else:
        await message.answer("‚ùå —Ç–∞–∫ —â–∞—Å –Ω–∏—á–µ–≥–æ –∏ –Ω–µ –∫–∞—á–∞–µ—Ç—Å—è –≤—Ä–æ–¥–µ (–æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤ –Ω–µ—Ç)")

@dp.callback_query(F.data.startswith("d_"))
async def process_download_callback(callback: types.CallbackQuery):
    try:
        track_data = json.loads(base64.b64decode(callback.data[2:]).decode('utf-8'))
        user_id = callback.from_user.id
        
        # Check if already downloading this specific track
        if track_data["url"] in download_tasks.get(user_id, {}):
            await callback.answer("—ç—Ç–æ—Ç —Ç—Ä–µ–∫ —É–∂–µ –∫–∞—á–∞–µ—Ç—Å—è –∏–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏", show_alert=True)
            return
            
        # Check queue as well
        if any(item[0]['url'] == track_data['url'] for item in download_queues.get(user_id, [])):
             await callback.answer("—ç—Ç–æ—Ç —Ç—Ä–µ–∫ —É–∂–µ –∫–∞—á–∞–µ—Ç—Å—è –∏–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏", show_alert=True)
             return
             
        active_downloads = sum(1 for task in download_tasks.get(user_id, {}).values() if not task.done())
        queue_size = len(download_queues.get(user_id, []))

        if active_downloads >= MAX_PARALLEL_DOWNLOADS:
            # NOTE: Queueing from search results is not fully integrated with the playlist system
            # For now, let's prevent queueing directly from search results to avoid complexity.
            # We could potentially create a 'single item playlist' entry in playlist_downloads,
            # but that adds overhead. Let's just download immediately if possible.
            await callback.answer(
                f"‚ùå —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–≥—Ä—É–∑–æ–∫ ({active_downloads}/{MAX_PARALLEL_DOWNLOADS}) –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ", 
                show_alert=True
            )
            # download_queues[user_id].append((track_data, callback.message)) # Disabled queueing from search for now
            # await callback.answer(
            #     f"‚è≥ –¥–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å ({queue_size+1}-–π) –∫–∞—á–∞—é {active_downloads}/{MAX_PARALLEL_DOWNLOADS}"
            # )
        else:
            # Using answer instead of sending a new message for initial status
            status_message = await callback.message.answer(f"‚è≥ –Ω–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞—Ç—å {track_data['title']} - {track_data['channel']}")
            if user_id not in download_tasks: download_tasks[user_id] = {} # Ensure user entry exists
            task = asyncio.create_task(
                # Pass callback.message as original_message_context
                download_track(user_id, track_data, callback.message, status_message, original_message_context=callback.message)
            )
            download_tasks[user_id][track_data["url"]] = task
            await callback.answer("–Ω–∞—á–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ")
            
    except json.JSONDecodeError:
         await callback.message.answer("‚ùå —á–µ—Ç –Ω–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∞ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∏—Å–∫–∞—Ç—å —Å–Ω–æ–≤–∞")
         await callback.answer()
    except Exception as e:
        print(f"Error in process_download_callback: {e}")
        await callback.message.answer(f"‚ùå –æ–π –æ—à–∏–±–∫–∞ {str(e).lower()}")
        await callback.answer()

@dp.callback_query(F.data.startswith("dl_"))
async def process_download_callback_with_index(callback: types.CallbackQuery):
    try:
        parts = callback.data.split("_")
        track_index = int(parts[1]) - 1
        search_id = parts[2]
        
        if search_id not in search_results:
            await callback.answer("‚ùå —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —É–∂–µ —É—Å—Ç–∞—Ä–µ–ª–∏ –Ω–∞–π–¥–∏ —Å–Ω–æ–≤–∞ –ø–ª–∑", show_alert=True)
            return
        
        tracks = search_results[search_id]
        if 0 <= track_index < len(tracks):
            track_data = tracks[track_index]
            user_id = callback.from_user.id

            # Check if already downloading this specific track
            if track_data["url"] in download_tasks.get(user_id, {}):
                await callback.answer("—ç—Ç–æ—Ç —Ç—Ä–µ–∫ —É–∂–µ –∫–∞—á–∞–µ—Ç—Å—è –∏–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏", show_alert=True)
                return
                
            # Check queue as well
            if any(item[0]['url'] == track_data['url'] for item in download_queues.get(user_id, [])):
                 await callback.answer("—ç—Ç–æ—Ç —Ç—Ä–µ–∫ —É–∂–µ –∫–∞—á–∞–µ—Ç—Å—è –∏–ª–∏ –≤ –æ—á–µ—Ä–µ–¥–∏", show_alert=True)
                 return

            active_downloads = sum(1 for task in download_tasks.get(user_id, {}).values() if not task.done())
            queue_size = len(download_queues.get(user_id, []))

            if active_downloads >= MAX_PARALLEL_DOWNLOADS:
                # Disable queueing from search for consistency
                await callback.answer(
                    f"‚ùå —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–≥—Ä—É–∑–æ–∫ ({active_downloads}/{MAX_PARALLEL_DOWNLOADS}) –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ", 
                    show_alert=True
                )
                # download_queues[user_id].append((track_data, callback.message))
                # await callback.answer(
                #     f"‚è≥ –¥–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å ({queue_size+1}-–π) –∫–∞—á–∞—é {active_downloads}/{MAX_PARALLEL_DOWNLOADS}"
                # )
            else:
                status_message = await callback.message.answer(f"‚è≥ –Ω–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞—Ç—å {track_data['title']} - {track_data['channel']}")
                if user_id not in download_tasks: download_tasks[user_id] = {} # Ensure user entry exists
                task = asyncio.create_task(
                    # Pass callback.message as original_message_context
                    download_track(user_id, track_data, callback.message, status_message, original_message_context=callback.message)
                )
                download_tasks[user_id][track_data["url"]] = task
                await callback.answer("–Ω–∞—á–∞–ª —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ")
        else:
            await callback.answer("‚ùå –Ω–µ –Ω–∞—à–µ–ª —Ç—Ä–µ–∫ –ø–æ —ç—Ç–æ–º—É –∏–Ω–¥–µ–∫—Å—É", show_alert=True)
            
    except IndexError:
         await callback.answer("‚ùå —á–µ—Ç –Ω–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è", show_alert=True)
    except Exception as e:
        print(f"Error in process_download_callback_with_index: {e}")
        await callback.answer(f"‚ùå –æ–π –æ—à–∏–±–∫–∞ {str(e).lower()}", show_alert=True)

@dp.callback_query(F.data.startswith("page_"))
async def process_page_callback(callback: types.CallbackQuery):
    try:
        parts = callback.data.split("_")
        page = int(parts[1])
        search_id = parts[2]
        
        if search_id not in search_results:
            await callback.answer("‚ùå —ç—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —É–∂–µ —Å—Ç–∞—Ä—ã–µ –ø–æ–∏—â–∏ –∑–∞–Ω–æ–≤–æ", show_alert=True)
            return
        
        tracks = search_results[search_id]
        keyboard = create_tracks_keyboard(tracks, page, search_id)
        
        await callback.message.edit_reply_markup(reply_markup=keyboard)
        await callback.answer()
    except (IndexError, ValueError):
        await callback.answer("‚ùå —á–µ—Ç –Ω–µ —Å–º–æ–≥ –ø–æ–Ω—è—Ç—å –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã", show_alert=True)
    except Exception as e:
        print(f"Error in process_page_callback: {e}")
        await callback.answer(f"‚ùå –±–ª–∏–Ω –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–ª–∏—Å—Ç—ã–≤–∞–Ω–∏–∏ {str(e).lower()}", show_alert=True)
        
@dp.callback_query(F.data == "info")
async def process_info_callback(callback: types.CallbackQuery):
    await callback.answer()

@dp.message()
async def handle_text(message: types.Message):
    # Ignore commands explicitly
    if message.text.startswith('/'):
        return
    
    text_content = message.text.strip()
    text_lower = text_content.lower()
    chat_type = message.chat.type

    # --- Group Chat Logic --- 
    if chat_type in ('group', 'supergroup'):
        # Check for '–º—É–∑—ã–∫–∞ ' command first
        if text_lower.startswith("–º—É–∑—ã–∫–∞ "):
            query = text_content[len("–º—É–∑—ã–∫–∞ "):].strip()
            if query:
                 await handle_group_search(message, query)
            else:
                 await message.reply("‚ùå –ø–æ—Å–ª–µ '–º—É–∑—ã–∫–∞' –Ω—É–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞.")
            return
        
        # Then check for any message containing a URL
        # Use regex to find the first http/https url
        url_match = re.search(r'https?://[\S]+', text_content) # Corrected regex to avoid \s
        if url_match:
            url = url_match.group(0)
            print(f"[Group URL Detect] Found URL: {url} in message: '{text_content}'")
            # --- Spotify URL Check ---
            if "open.spotify.com" in url:
                 if SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET:
                      await handle_spotify_url(message, url) # Call the handler
                 else:
                      await message.reply("‚ùå –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Å—ã–ª–æ–∫ spotify –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç client id/secret)")
                 return # Exit after handling or notifying about Spotify link
            # --- Fallback to generic URL download ---
            else:
                 await handle_url_download(message, url)
            return # Exit after handling generic URL
        
        # Ignore other messages in groups
        return 
            
    # --- Private Chat Logic --- 
    elif chat_type == 'private':
        # Check if it's a Spotify URL first
        if "open.spotify.com" in text_content and text_content.startswith(('http://', 'https://')):
             if SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET:
                  await handle_spotify_url(message, text_content) # Call the handler
             else:
                  await message.answer("‚ùå –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Å—ã–ª–æ–∫ spotify –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç client id/secret)")
             return # Exit after handling or notifying about Spotify link
             
        # Check if it's any other URL 
        elif text_content.startswith(('http://', 'https://')):
            await handle_url_download(message, text_content) # Pass URL directly
            return # Exit after handling generic URL
        
        else:
            # Treat as search query
            query = text_content
            searching_message = await message.answer("üîç –∏—â—É –º—É–∑—ã–∫—É...")
            search_id = str(uuid.uuid4())
            # Search all sources concurrently
            try:
                max_results_per_source = MAX_TRACKS // 4 # Divide budget among 4 sources now
                spotify_results, youtube_results, soundcloud_results, bandcamp_results = await asyncio.gather(
                    search_spotify(query, max_results_per_source), # Added Spotify search
                    search_youtube(query, max_results_per_source),
                    search_soundcloud(query, max_results_per_source),
                    search_bandcamp(query, max_results_per_source)
                )

                # Prioritize Spotify -> SoundCloud -> Bandcamp -> YouTube results
                combined_results = []
                # Add Spotify results first
                for sp_track in spotify_results:
                     if 'source' not in sp_track: # Should have source already, but defensive check
                         sp_track['source'] = 'spotify'
                     combined_results.append(sp_track)
                # Add SoundCloud results
                for sc_track in soundcloud_results:
                    if 'source' not in sc_track:
                        sc_track['source'] = 'soundcloud'
                    combined_results.append(sc_track)
                # Then add Bandcamp results
                for bc_track in bandcamp_results:
                     if 'source' not in bc_track:
                         bc_track['source'] = 'bandcamp'
                     combined_results.append(bc_track)
                # Then add YouTube results
                for yt_track in youtube_results:
                    if 'source' not in yt_track:
                        yt_track['source'] = 'youtube'
                    combined_results.append(yt_track)

                # Limit total results if needed (redundant if MAX_TRACKS was respected by sources?)
                # combined_results = combined_results[:MAX_TRACKS]

                if not combined_results:
                    await message.answer("‚ùå —á–µ—Ç –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å") # Updated message
                    await bot.delete_message(chat_id=searching_message.chat.id, message_id=searching_message.message_id)
                    return
                
                search_results[search_id] = combined_results
                keyboard = create_tracks_keyboard(combined_results, 0, search_id)
                await bot.edit_message_text(
                    chat_id=searching_message.chat.id,
                    message_id=searching_message.message_id,
                    text=f"üéµ –Ω–∞—à–µ–ª –¥–ª—è —Ç–µ–±—è {len(combined_results)} —Ç—Ä–µ–∫–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É ¬´{query}¬ª ‚¨á",
                    reply_markup=keyboard
                )
            except Exception as e:
                 print(f"Error during private search for query '{query}': {e}")
                 # Add traceback print
                 print(traceback.format_exc())
                 await bot.edit_message_text(
                     chat_id=searching_message.chat.id, 
                     message_id=searching_message.message_id,
                     text=f"‚ùå –±–ª–∏–Ω –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}"
                 )
            # Return should be outside the except block but inside the else block
            return # End of private search logic

# --- Spotify URL Handler ---
async def handle_spotify_url(message: types.Message, url: str):
    print(f"[Spotify Handler] Detected Spotify URL: {url}")
    status_message = await message.answer("‚è≥ –ø–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ spotify –∏ –∏—â—É —Ç—Ä–µ–∫–∏...")
    user_id = message.from_user.id
    loop = asyncio.get_running_loop()

    try:
        # Initialize Spotdl
        # Note: Ensure headless=True if running without a display
        #       Ensure ffmpeg is available (using path from ydl_opts for consistency?)
        spotdl_client = Spotdl(
            client_id=SPOTIFY_CLIENT_ID, 
            client_secret=SPOTIFY_CLIENT_SECRET, 
            headless=True, 
            # downloader_settings={'ffmpeg': ydl_opts.get('ffmpeg_location', 'ffmpeg')} # Pass ffmpeg path if needed
        )
        
        # Fetch song info using spotdl's search (blocking operation)
        # Assuming spotdl_client.search returns a list of Song objects or similar dicts
        print(f"[Spotify Handler] Querying spotdl for: {url}")
        # The search method might block, run in executor
        songs_list = await loop.run_in_executor(None, spotdl_client.search, [url])
        print(f"[Spotify Handler] Found {len(songs_list)} tracks from spotdl.")

        if not songs_list:
            await bot.edit_message_text(
                "‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç—Ä–µ–∫–∏ –ø–æ —ç—Ç–æ–π —Å—Å—ã–ª–∫–µ spotify —Å –ø–æ–º–æ—â—å—é spotdl",
                chat_id=status_message.chat.id,
                message_id=status_message.message_id
            )
            return

        # Determine if it's a single track or playlist/album/etc.
        is_single_track = len(songs_list) == 1
        # Extract a general title (e.g., playlist name if available, fallback)
        # Spotdl's Song object might have album/playlist attributes, need to check its structure
        # For now, use a generic title
        source_title = songs_list[0].album_name if hasattr(songs_list[0], 'album_name') and not is_single_track else \
                       songs_list[0].name if is_single_track else \
                       "Spotify Selection"

        # Prepare tracks for our internal queue system
        processed_tracks_for_playlist = []
        skipped_count = 0
        
        for index, song_obj in enumerate(songs_list):
            # Extract required info based on assumed spotdl Song object structure
            try:
                entry_title = song_obj.name
                entry_artist = song_obj.artists[0] if song_obj.artists else "Unknown Artist"
                # IMPORTANT ASSUMPTION: song_obj.download_url contains the URL found by spotdl (e.g., YouTube)
                entry_url = getattr(song_obj, 'download_url', None) 
                
                # Basic validation (URL is crucial)
                if not entry_url or not entry_title:
                    print(f"[Spotify Handler] Skipping track '{entry_title}' due to missing URL or Title. Data: {song_obj}")
                    skipped_count += 1
                    continue
                    
                processed_tracks_for_playlist.append({
                    'original_index': index, # Keep original order if needed
                    'url': entry_url, # This is the YouTube/etc. URL
                    'title': entry_title,
                    'artist': entry_artist, 
                    'status': 'pending',
                    'error_message': None,
                    'file_path': None,
                    'source': 'spotify' # Indicate origin
                })
            except Exception as parse_err:
                print(f"[Spotify Handler] Error processing spotdl song object: {parse_err}. Data: {song_obj}")
                skipped_count += 1
                continue

        total_processed = len(processed_tracks_for_playlist)
        if total_processed == 0:
             await bot.edit_message_text(
                f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ '{source_title}' (–ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}).",
                chat_id=status_message.chat.id,
                message_id=status_message.message_id
             )
             return

        # Limit total tracks if necessary (using existing constant)
        limit_message = ""
        if total_processed > MAX_TRACKS:
            limit_message = f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {total_processed} —Ç—Ä–µ–∫–æ–≤. –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ {MAX_TRACKS}."
            processed_tracks_for_playlist = processed_tracks_for_playlist[:MAX_TRACKS]
            total_processed = MAX_TRACKS

        # --- If single track, download directly --- 
        if is_single_track and total_processed == 1:
            track_to_download = processed_tracks_for_playlist[0]
            track_data_for_dl = {
                 "title": track_to_download['title'],
                 "channel": track_to_download['artist'],
                 "url": track_to_download['url'],
                 "source": track_to_download['source']
            }
            # Edit status before starting download
            await bot.edit_message_text(
                 f"‚è≥ –ù–∞–π–¥–µ–Ω —Ç—Ä–µ–∫ '{track_data_for_dl['title']} - {track_data_for_dl['channel']}'. –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ...",
                 chat_id=status_message.chat.id,
                 message_id=status_message.message_id
            )
            if user_id not in download_tasks: download_tasks[user_id] = {}
            # Pass necessary context to download_track
            task = asyncio.create_task(
                download_track(
                    user_id, 
                    track_data_for_dl, 
                    callback_message=None, # No callback message here
                    status_message=status_message, # Pass the status message
                    original_message_context=message, # Pass the original message 
                    playlist_download_id=None # Not part of a playlist download batch
                )
            )
            download_tasks[user_id][track_data_for_dl["url"]] = task
            # No callback.answer() here
            return # Finished handling single track

        # --- If multiple tracks (Playlist/Album/Artist) --- 
        else:
            playlist_download_id = str(uuid.uuid4())
            # --- Create entry in playlist_downloads ---
            playlist_downloads[playlist_download_id] = {
                'user_id': user_id,
                'original_message_id': message.message_id,
                'chat_id': message.chat.id,
                'status_message_id': status_message.message_id,
                'playlist_title': source_title, # Use extracted title
                'total_tracks': total_processed, 
                'completed_tracks': 0,
                'tracks': processed_tracks_for_playlist, 
                'final_status_message_id': None
            }

            # Update status message
            status_text = f"""‚è≥ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_processed} —Ç—Ä–µ–∫–æ–≤ –≤ '{source_title}'.
{limit_message}
–î–æ–±–∞–≤–ª—è—é –≤ –æ—á–µ—Ä–µ–¥—å..."""
            await bot.edit_message_text(
                status_text,
                chat_id=status_message.chat.id,
                message_id=status_message.message_id
            )

            # --- Queue tracks for download ---
            queued_count = 0
            if user_id not in download_queues: download_queues[user_id] = []

            for track_to_queue in processed_tracks_for_playlist:
                track_data_for_queue = {
                    "title": track_to_queue['title'],
                    "channel": track_to_queue['artist'],
                    "url": track_to_queue['url'], # The YouTube/etc. URL
                    "source": track_to_queue['source']
                }
                download_queues[user_id].append((track_data_for_queue, playlist_download_id))
                queued_count += 1

            print(f"[Spotify Handler] Queued {queued_count} tracks for playlist {playlist_download_id} ('{source_title}') for user {user_id}.")

            # Start processing the queue if possible
            if user_id not in download_tasks: download_tasks[user_id] = {}
            active_downloads = sum(1 for task in download_tasks.get(user_id, {}).values() if not task.done())

            if queued_count > 0 and active_downloads < MAX_PARALLEL_DOWNLOADS:
                 print(f"[Spotify Handler] Triggering queue processing for user {user_id}")
                 asyncio.create_task(process_download_queue(user_id))
            elif queued_count > 0:
                 print(f"[Spotify Handler] Queue for user {user_id} will be processed as existing downloads complete.")
                 
            return # Finished handling playlist/album

    except Exception as e:
        print(f"[Spotify Handler] Error handling Spotify URL {url}: {e}")
        print(traceback.format_exc())
        try:
            await bot.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Å—ã–ª–∫–∏ spotify: {e}",
                chat_id=status_message.chat.id,
                message_id=status_message.message_id
            )
        except Exception as final_err:
            print(f"[Spotify Handler] Failed to edit final error message: {final_err}")
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Å—ã–ª–∫–∏ spotify: {e}")


# --- Generic URL Handler (yt-dlp based) ---
async def handle_url_download(message: types.Message, url: str):
    """Handles messages identified as URLs (or via '–º–µ–¥–∏–∞–∫–æ—Ç') to initiate download."""
    # Use reply for group trigger, answer for direct URL in private
    reply_method = message.reply if message.chat.type != 'private' else message.answer
    status_message = await reply_method(f"‚è≥ –ø—ã—Ç–∞—é—Å—å —Å–∫–∞—á–∞—Ç—å –º–µ–¥–∏–∞ –ø–æ —Å—Å—ã–ª–∫–µ {url[:50]}...", disable_web_page_preview=True)
    
    # Pass the original message for context if needed later, and the status message to update
    await download_media_from_url(url, message, status_message)

async def handle_group_search(message: types.Message, query: str):
    """Handles '–º—É–∑—ã–∫–∞–∫–æ—Ç' command in groups."""
    status_message = await message.reply("üîç –∏—â—É –º—É–∑—ã–∫—É...")
    search_id = str(uuid.uuid4())
    
    try:
        max_results_per_source = MAX_TRACKS // 4 # Divide budget among 4 sources now
        spotify_results, youtube_results, soundcloud_results, bandcamp_results = await asyncio.gather(
            search_spotify(query, max_results_per_source), # Added Spotify search
            search_youtube(query, max_results_per_source),
            search_soundcloud(query, max_results_per_source),
            search_bandcamp(query, max_results_per_source)
        )

        # Prioritize Spotify -> SoundCloud -> Bandcamp -> YouTube results
        combined_results = []
        # Add Spotify results first
        for sp_track in spotify_results:
             if 'source' not in sp_track:
                 sp_track['source'] = 'spotify'
             combined_results.append(sp_track)
        # Add SoundCloud results
        for sc_track in soundcloud_results:
            if 'source' not in sc_track:
                sc_track['source'] = 'soundcloud'
            combined_results.append(sc_track)
        # Then add Bandcamp results
        for bc_track in bandcamp_results:
            if 'source' not in bc_track:
                bc_track['source'] = 'bandcamp'
            combined_results.append(bc_track)
        # Then add YouTube results
        for yt_track in youtube_results:
            if 'source' not in yt_track:
                yt_track['source'] = 'youtube'
            combined_results.append(yt_track)

        # Limit total results if needed
        # combined_results = combined_results[:MAX_TRACKS]

        if not combined_results:
            await bot.edit_message_text(
                chat_id=status_message.chat.id,
                message_id=status_message.message_id,
                text="‚ùå –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–µ–ª –ø–æ —Ç–≤–æ–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑" # Updated message
            )
            return

        search_results[search_id] = combined_results
        keyboard = create_tracks_keyboard(combined_results, 0, search_id)
        await bot.edit_message_text(
            chat_id=status_message.chat.id,
            message_id=status_message.message_id,
            text=f"üéµ –Ω–∞—à–µ–ª –¥–ª—è —Ç–µ–±—è {len(combined_results)} —Ç—Ä–µ–∫–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É ¬´{query}¬ª ‚¨á",
        reply_markup=keyboard
    )

    except Exception as e:
        print(f"Error during group search for query '{query}': {e}")
        await bot.edit_message_text(
            chat_id=status_message.chat.id,
            message_id=status_message.message_id,
            text=f"‚ùå –±–ª–∏–Ω –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}"
        )

async def download_media_from_url(url: str, original_message: types.Message, status_message: types.Message):
    """Downloads media (audio or video) from a direct URL using yt-dlp.
    Handles both single media links and playlist links.
    For playlists, queues all tracks and sends them together upon completion."""
    loop = asyncio.get_running_loop()
    user_id = original_message.from_user.id # Get user_id early

    download_uuid = str(uuid.uuid4()) # Used for single file downloads
    temp_dir = tempfile.gettempdir()
    base_temp_path = os.path.join(temp_dir, f"media_{download_uuid}")
    actual_downloaded_path = None # Initialize here to prevent NameError
    temp_path = None # Also keep this initialized as it might be used in error messages

    # Options for general media download (Try 'best' first, then specific video/audio combos)
    media_ydl_opts = {
        'format': 'best/bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio/best[ext=mp4]', # Added 'best/' at the beginning
        'outtmpl': base_temp_path + '.%(ext)s', # Let ytdl determine extension
        'quiet': False,
        'verbose': True,
        'no_warnings': False,
        'prefer_ffmpeg': True,
        'nocheckcertificate': True,
        'ignoreerrors': True, # Important for trying potentially unsupported URLs
        'extract_flat': False,
        'ffmpeg_location': '/usr/bin/ffmpeg',
        # Add merge output format if separate streams are downloaded
        'merge_output_format': 'mp4', 
        # No audio-specific postprocessor here initially
    }

    try:
        # --- 1. Get Info (Optional but good for metadata/title) --- 
        extracted_info = None
        try:
            # Use slightly different opts just for info extraction to avoid downloading accidentally
            info_opts = {
                'quiet': True, 
                'no_warnings': True, 
                'nocheckcertificate': True, 
                'ignoreerrors': True, 
                'extract_flat': False # Need full entries for playlist detection
            }
            with yt_dlp.YoutubeDL(info_opts) as ydl:
                extracted_info = await loop.run_in_executor(None, lambda: ydl.extract_info(url, download=False))
                if not extracted_info:
                    print(f"[URL Download] Could not extract info for {url}")
        except Exception as info_err:
            print(f"[URL Download] Error extracting info for {url}: {info_err}")
            # Continue anyway, try downloading

        # --- Check if it's a playlist BEFORE attempting single download ---
        if extracted_info and extracted_info.get('_type') == 'playlist':
            playlist_download_id = str(uuid.uuid4())
            playlist_title = extracted_info.get('title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–ª–µ–π–ª–∏—Å—Ç')
            entries = extracted_info.get('entries', [])
            
            if not entries:
                await bot.edit_message_text(
                    f"‚ùå –ü–ª–µ–π–ª–∏—Å—Ç '{playlist_title}' –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤.",
                    chat_id=status_message.chat.id,
                    message_id=status_message.message_id
                )
                return # Exit function

            processed_tracks_for_playlist = []
            skipped_count = 0
            failed_initial_parse_count = 0

            # --- Filter and prepare track list for the playlist tracker ---
            for index, entry in enumerate(entries):
                if not entry:
                    failed_initial_parse_count += 1
                    continue

                # --- Get URL for the track (YouTube playlist specific logic) ---
                entry_url = entry.get('webpage_url')
                if not entry_url:
                    video_id = entry.get('id')
                    if video_id:
                        entry_url = f"https://www.youtube.com/watch?v={video_id}"
                        print(f"[Playlist Prep] Using constructed URL: {entry_url}")
                    else:
                        # If no webpage_url and no id, we cannot proceed
                        print(f"[Playlist Prep DEBUG] Skipping entry. Reason: Missing webpage_url and id.")
                        print(f"[Playlist Prep DEBUG] Entry data: {entry}")
                        failed_initial_parse_count += 1
                        continue
                # -------------------------------------------------------------

                entry_title = entry.get('title', None)
                # entry_duration = entry.get('duration', 0) # Keep duration if needed later, but don't filter here

                # Artist extraction (simplified for playlist prep)
                entry_artist = "Unknown Artist"
                source_key = entry.get('ie_key', '').lower()
                if source_key == 'soundcloud':
                     raw_title = entry_title if entry_title else 'Unknown Title'
                     sc_uploader = entry.get('uploader', None)
                     if ' - ' in raw_title:
                         parts = raw_title.split(' - ', 1)
                         potential_artist = parts[0].strip()
                         potential_title = parts[1].strip()
                         if potential_artist and potential_title:
                             entry_title = potential_title; entry_artist = potential_artist
                         else: entry_title = raw_title; entry_artist = sc_uploader if sc_uploader else "Unknown Artist"
                     elif sc_uploader: entry_title = raw_title; entry_artist = sc_uploader
                     else: entry_title = raw_title; entry_artist = "Unknown Artist"
                elif source_key == 'bandcamp':
                     entry_artist = entry.get('artist', entry.get('uploader', 'Unknown Artist'))
                     raw_title = entry_title if entry_title else 'Unknown Title'
                     if entry_artist == 'Unknown Artist' and ' - ' in raw_title:
                          parts = raw_title.split(' - ', 1)
                          if parts[0].strip() and parts[1].strip(): entry_title = parts[1].strip(); entry_artist = parts[0].strip()
                          else: entry_title = raw_title
                     else: entry_title = raw_title
                else: # YouTube/Other
                    original_raw_title = entry_title # Store original title before attempting extraction
                    if entry_title: # Only extract if title exists
                        extracted_title, extracted_artist = extract_title_and_artist(entry_title)
                        # Use extracted results only if title is not 'Unknown Title'
                        if extracted_title != 'Unknown Title':
                             entry_title = extracted_title
                             entry_artist = extracted_artist
                             # Fallback to uploader if extracted artist is unknown
                             if entry_artist == "Unknown Artist": 
                                 entry_artist = entry.get('uploader', 'Unknown Artist')
                        else:
                            # Extraction failed, use original title and uploader as artist
                            print(f"[Playlist Prep] Extraction failed for '{original_raw_title}', using raw title.")
                            entry_title = original_raw_title 
                            entry_artist = entry.get('uploader', 'Unknown Artist') 
                    else: 
                        entry_title = 'Unknown Title' # Handle case where original title was missing
                        entry_artist = entry.get('uploader', 'Unknown Artist')

                # Final validation before queuing
                if not entry_url or not entry_title or entry_title == 'Unknown Title': # Check for None/empty title too
                    # Removed detailed debug logging here as URL issue is handled above
                    print(f"[Playlist Prep] Warning: Skipping entry in '{playlist_title}' due to missing URL or essential Title after processing: {entry}")
                    failed_initial_parse_count += 1
                    continue

                # Add prepared track data to the list for this playlist
                processed_tracks_for_playlist.append({
                    'original_index': index,
                    'url': entry_url,
                    'title': entry_title,
                    'artist': entry_artist, # Use 'artist' key internally
                    'status': 'pending',
                    'error_message': None,
                    'file_path': None,
                    'source': source_key # Store source for potential future use
                })

            # Limit total tracks AFTER initial processing
            total_processed = len(processed_tracks_for_playlist)
            if total_processed == 0:
                 await bot.edit_message_text(
                    f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–ª–µ–π–ª–∏—Å—Ç–µ '{playlist_title}'.", # Removed duration mention
                    chat_id=status_message.chat.id,
                    message_id=status_message.message_id
                 )
                 return

            limit_message = ""
            if total_processed > MAX_TRACKS:
                limit_message = f"‚ö†Ô∏è –í –ø–ª–µ–π–ª–∏—Å—Ç–µ –Ω–∞–π–¥–µ–Ω–æ {total_processed} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç—Ä–µ–∫–æ–≤. –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–æ–ª—å–∫–æ {MAX_TRACKS}."
                processed_tracks_for_playlist = processed_tracks_for_playlist[:MAX_TRACKS]
                total_processed = MAX_TRACKS # Update count after slicing

            # --- Create entry in playlist_downloads ---
            playlist_downloads[playlist_download_id] = {
                'user_id': user_id,
                'original_message_id': original_message.message_id, # Store IDs for reference
                'chat_id': original_message.chat.id,
                'status_message_id': status_message.message_id,
                'playlist_title': playlist_title,
                'total_tracks': total_processed, # Actual number to be queued
                'completed_tracks': 0,
                'tracks': processed_tracks_for_playlist, # The filtered, ordered list
                'final_status_message_id': None # To store ID of the final "–û—Ç–ø—Ä–∞–≤–ª—è—é..." message
            }

            # Update status message
            status_text = f"""‚è≥ –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–ª–µ–π–ª–∏—Å—Ç '{playlist_title}'.
–ù–∞–π–¥–µ–Ω–æ {total_processed} —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.
{limit_message}
–î–æ–±–∞–≤–ª—è—é –≤ –æ—á–µ—Ä–µ–¥—å..."""
            await bot.edit_message_text(
                status_text,
                chat_id=status_message.chat.id,
                message_id=status_message.message_id
            )

            # --- Queue tracks for download ---
            queued_count = 0
            # Ensure user queue exists
            if user_id not in download_queues: download_queues[user_id] = []

            for track_to_queue in processed_tracks_for_playlist:
                # Construct track_data needed by download_track/process_queue
                track_data_for_queue = {
                    "title": track_to_queue['title'],
                    "channel": track_to_queue['artist'], # download_track expects 'channel'
                    "url": track_to_queue['url'],
                    "source": track_to_queue['source']
                }
                # Add to user's queue with playlist_id
                download_queues[user_id].append((track_data_for_queue, playlist_download_id))
                queued_count += 1

            print(f"[Playlist Prep] Queued {queued_count} tracks for playlist {playlist_download_id} ('{playlist_title}') for user {user_id}.")

            # Start processing the queue if possible
            # Need to manage download_tasks initialization potentially here too
            if user_id not in download_tasks: download_tasks[user_id] = {}
            active_downloads = sum(1 for task in download_tasks.get(user_id, {}).values() if not task.done())

            if queued_count > 0 and active_downloads < MAX_PARALLEL_DOWNLOADS:
                 print(f"[Playlist Prep] Triggering queue processing for user {user_id}")
                 # Use create_task to not block
                 asyncio.create_task(process_download_queue(user_id))
            elif queued_count > 0:
                 print(f"[Playlist Prep] Queue for user {user_id} will be processed as existing downloads complete.")

            return # IMPORTANT: Exit after handling playlist queuing

        # --- IF NOT A PLAYLIST ---
        # --- 2. Download (Single Media) ---
        # (The rest of the original single-file download logic follows)
        # ... (ensure status message edit happens only here for single files) ...
        try:
             await bot.edit_message_text(
                 f"‚è≥ –∫–∞—á–∞—é –º–µ–¥–∏–∞",
                 chat_id=status_message.chat.id,
                 message_id=status_message.message_id
             )
        except Exception as e:
             print(f"[URL Download] Warning: Failed to edit status message for single download (maybe deleted?): {e}")
             # Proceed silently, user got the initial "–ø—ã—Ç–∞—é—Å—å —Å–∫–∞—á–∞—Ç—å" message.
             pass

    except yt_dlp.utils.DownloadError as dl_err:
         # Catch specific yt-dlp download errors
         print(f"ERROR yt-dlp DownloadError for {url}: {dl_err}")
         error_text_base = f"‚ùå –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ yt-dlp –≤–æ–∑–º–æ–∂–Ω–æ —Å—Å—ã–ª–∫–∞ –±–∏—Ç–∞—è –∏–ª–∏ —Å–∞–π—Ç –∏–∑–º–µ–Ω–∏–ª—Å—è"
         # Attempt to extract a more specific error message if available
         # yt-dlp often includes the reason in the error message string
         error_msg_lower = str(dl_err).lower()
         if 'forbidden' in error_msg_lower or 'unavailable' in error_msg_lower:
             error_text_base = f"‚ùå –≤–∏–¥–µ–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –∏–ª–∏ –¥–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω"
         elif 'private' in error_msg_lower:
             error_text_base = f"‚ùå —ç—Ç–æ –ø—Ä–∏–≤–∞—Ç–Ω–æ–µ –≤–∏–¥–µ–æ –Ω—É–∂–µ–Ω –ª–æ–≥–∏–Ω"
         elif 'ip address is blocked' in error_msg_lower: # Check for IP block specifically
             error_text_base = f"‚ùå —Å–µ—Ä–≤–∏—Å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –¥–æ—Å—Ç—É–ø —Å ip –∞–¥—Ä–µ—Å–∞ –±–æ—Ç–∞ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ –∏–ª–∏ –¥—Ä—É–≥—É—é —Å—Å—ã–ª–∫—É"
             
         error_text = error_text_base.replace(',', '').replace('.', '') # Apply style
         try:
             await bot.edit_message_text(
                 chat_id=status_message.chat.id,
                 message_id=status_message.message_id,
                 text=error_text,
                 disable_web_page_preview=True
             )
         except Exception as edit_error:
             print(f"Failed to edit message for DownloadError: {edit_error}")
             # Fallback to sending new message
             try:
                  await original_message.answer(error_text, disable_web_page_preview=True)
                  await bot.delete_message(chat_id=status_message.chat.id, message_id=status_message.message_id)
             except Exception as send_error:
                  print(f"[URL Download] Warning: Failed to send new message for DownloadError: {send_error}")

    except Exception as e:
        # Generic exception handler remains the same
        print(f"ERROR during URL download/processing for {url}: {e}\\n{traceback.format_exc()}")
        error_text_base = f"‚ùå –±–ª–∏–Ω –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏/–æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Å—ã–ª–∫–∏ {str(e).lower()}"
        if "Unsupported URL" in str(e):
             error_text_base = f"‚ùå –∏–∑–≤–∏–Ω–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ–¥–∏–∞ {url[:60]}"
        elif "Request Entity Too Large" in str(e): # Handle this specific error nicely
             error_text_base = f"‚ùå —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ —Ç–µ–ª–µ–≥—Ä–∞–º (–ª–∏–º–∏—Ç 50 –º–±)"
        elif "File too large" in str(e): # Handle our custom large file exception
             error_text_base = f"‚ùå {str(e).lower()}" # Already formatted
        elif "whoops" in str(e).lower() or "unable to download video data" in str(e).lower():
             error_text_base = f"‚ùå –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Å—ã–ª–∫–µ –≤–æ–∑–º–æ–∂–Ω–æ –æ–Ω–∞ –±–∏—Ç–∞—è –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç –ª–æ–≥–∏–Ω–∞"
             
        error_text = error_text_base.replace(',', '').replace('.', '') # Apply final cleanup
        if len(error_text) > 4000: 
            error_text = error_text[:3995] + "..." # Adjusted length for ellipsis
        try:
            await bot.edit_message_text(
                chat_id=status_message.chat.id,
                message_id=status_message.message_id,
                text=error_text,
                disable_web_page_preview=True
            )
        except Exception as edit_error:
            print(f"Failed to edit message for error: {edit_error}")
            # Try sending a new message if editing fails
            try:
                 await original_message.answer(error_text, disable_web_page_preview=True)
                 # Try deleting the original status message if possible
                 await bot.delete_message(chat_id=status_message.chat.id, message_id=status_message.message_id)
            except Exception as send_error:
                 print(f"[URL Download] Warning: Failed to send new message for error: {send_error}")

    finally:
        # Cleanup for SINGLE file downloads only. Playlist files are handled by send_completed_playlist/cancel.
        if actual_downloaded_path and os.path.exists(actual_downloaded_path):
            # Check if it was a playlist (unlikely to reach here, but safeguard)
            # The check `if extracted_info and extracted_info.get('_type') == 'playlist':` should prevent this block from running for playlists.
            # So, if we are here, it should be a single download. 
            print(f"[URL Cleanup] Attempting to remove single download file: {actual_downloaded_path}")
            try:
                os.remove(actual_downloaded_path)
                print(f"[URL Cleanup] Successfully removed: {actual_downloaded_path}")
            except Exception as remove_error:
                print(f"[URL Cleanup] Warning: Failed to remove single download file {actual_downloaded_path}: {remove_error}")
        # Removed Task Management and Queue Processing logic from here - it belongs in download_track's finally block.

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main()) 
